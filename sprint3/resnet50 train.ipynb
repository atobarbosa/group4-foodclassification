{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da70169-0f90-48db-bc3f-2cec983b1001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "from mindcv.models import create_model\n",
    "from mindcv.loss import create_loss\n",
    "from mindcv.optim import create_optimizer\n",
    "from mindcv.data import create_transforms\n",
    "from mindspore import context, ops\n",
    "from mindspore.dataset import ImageFolderDataset\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c4b46a-5b79-4bde-9379-d705b12dff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(20904:20908,MainProcess):2025-10-10-22:54:22.625.704 [mindspore\\context.py:1412] For 'context.set_context', the parameter 'device_target' will be deprecated and removed in a future version. Please use the api mindspore.set_device() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MindSpore device target: CPU\n"
     ]
    }
   ],
   "source": [
    "context.set_context(mode=ms.PYNATIVE_MODE, device_target=\"GPU\")  # change to \"GPU\" if available\n",
    "print(\"‚úÖ MindSpore device target:\", context.get_context(\"device_target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff221d4-8cba-4244-89b2-8d4248f55366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded dataset successfully! 1200 training samples, 1200 validation samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from mindspore.dataset import ImageFolderDataset\n",
    "\n",
    "train_dir = \"../train\"\n",
    "val_dir = \"../val\"\n",
    "\n",
    "assert os.path.isdir(train_dir), f\"‚ùå Train directory not found: {train_dir}\"\n",
    "assert os.path.isdir(val_dir), f\"‚ùå Validation directory not found: {val_dir}\"\n",
    "\n",
    "dataset_train = ImageFolderDataset(dataset_dir=train_dir, shuffle=True, decode=False)\n",
    "dataset_val = ImageFolderDataset(dataset_dir=val_dir, shuffle=False, decode=False)\n",
    "\n",
    "print(f\"‚úÖ Loaded dataset successfully! {dataset_train.get_dataset_size()} training samples, {dataset_val.get_dataset_size()} validation samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9b649fa-cb21-4ac0-bd91-61742c650d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datasets decoded and transformed successfully!\n"
     ]
    }
   ],
   "source": [
    "from mindspore.dataset.vision import Inter, Decode, Resize, Normalize, HWC2CHW\n",
    "from mindspore.dataset.transforms import TypeCast\n",
    "import mindspore.common.dtype as mstype\n",
    "\n",
    "mean = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "std = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# ‚úÖ Include Decode() FIRST\n",
    "transforms_train = [\n",
    "    Decode(),\n",
    "    Resize((224, 224), interpolation=Inter.BICUBIC),\n",
    "    Normalize(mean=mean, std=std),\n",
    "    HWC2CHW(),\n",
    "    TypeCast(mstype.float32)\n",
    "]\n",
    "\n",
    "transforms_val = [\n",
    "    Decode(),\n",
    "    Resize((224, 224), interpolation=Inter.BICUBIC),\n",
    "    Normalize(mean=mean, std=std),\n",
    "    HWC2CHW(),\n",
    "    TypeCast(mstype.float32)\n",
    "]\n",
    "\n",
    "dataset_train = dataset_train.map(operations=transforms_train, input_columns=\"image\")\n",
    "dataset_train = dataset_train.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset_val = dataset_val.map(operations=transforms_val, input_columns=\"image\")\n",
    "dataset_val = dataset_val.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "print(\"‚úÖ Datasets decoded and transformed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e20bbb7-7a73-4965-957e-e76e9a324b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(20904:20908,MainProcess):2025-10-10-22:54:26.821.357 [mindspore\\train\\serialization.py:1789] For 'load_param_into_net', 2 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint.\n",
      "[WARNING] ME(20904:20908,MainProcess):2025-10-10-22:54:26.821.357 [mindspore\\train\\serialization.py:1793] ['classifier.weight', 'classifier.bias'] are not loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created: ResNet50 with 6 classes\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Model Setup ---\n",
    "num_classes = 6\n",
    "model = create_model(model_name=\"resnet50\", num_classes=num_classes, pretrained=True)\n",
    "print(\"‚úÖ Model created: ResNet50 with\", num_classes, \"classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e4667bb-cd0d-4e8a-84ff-d347eed54dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Loss and Optimizer ---\n",
    "loss_fn = create_loss(name=\"CE\")\n",
    "optimizer = create_optimizer(model.trainable_params(), opt=\"adam\", lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40bdf8b1-b7b1-4f52-bc5e-9b2f9703d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Training and Validation Functions ---\n",
    "def train_one_epoch(model, dataset, loss_fn, optimizer):\n",
    "    model.set_train(True)\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in dataset.create_dict_iterator():\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        def forward_fn(inputs, targets):\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            return loss, outputs\n",
    "\n",
    "        grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True)\n",
    "        (loss, outputs), grads = grad_fn(images, labels)\n",
    "        optimizer(grads)\n",
    "\n",
    "        total_loss += loss.asnumpy()\n",
    "        preds = outputs.asnumpy().argmax(axis=1)\n",
    "        total_correct += np.sum(preds == labels.asnumpy())\n",
    "        total_samples += labels.shape[0]\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def validate(model, dataset):\n",
    "    model.set_train(False)\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for batch in dataset.create_dict_iterator():\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"label\"]\n",
    "        outputs = model(images)\n",
    "        preds = outputs.asnumpy().argmax(axis=1)\n",
    "        total_correct += np.sum(preds == labels.asnumpy())\n",
    "        total_samples += labels.shape[0]\n",
    "    return total_correct / total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46167497-e969-4060-98d5-ebba7c51fe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training for 1 epochs...\n",
      "Epoch [1/1] | Loss: 0.189583 | Train Acc: 0.3708 | Val Acc: 0.3175\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Training Loop ---\n",
    "num_epochs = 1\n",
    "print(\"üöÄ Starting training for\", num_epochs, \"epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, dataset_train, loss_fn, optimizer)\n",
    "    val_acc = validate(model, dataset_val)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {train_loss:.6f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70ca75b0-bdcf-425d-bae5-221e8a78ef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training complete. Checkpoint saved to ../models/resnet50_food.ckpt\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Save Checkpoint ---\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "ms.save_checkpoint(model, \"../models/resnet50_food.ckpt\")\n",
    "print(\"‚úÖ Training complete. Checkpoint saved to ../models/resnet50_food.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f732f-27e5-4d82-b85b-1a272c716c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
